# 패스파인더 AI 파이썬 자율주행 키트 (Pathfinder Autonomous Kit)

라즈베리파이 기반 교육용 자율주행 로봇 키트로, 기초 하드웨어 제어부터 고급 AI 알고리즘까지 단계별로 학습할 수 있는 종합적인 로보틱스 교육 플랫폼입니다.

## 🎯 프로젝트 개요

이 프로젝트는 **7단계 커리큘럼**을 통해 자율주행 로봇을 구축하고 프로그래밍하는 방법을 학습합니다:
- 하드웨어 조립 → 개별 컴포넌트 테스트 → 통합 → 장애물 회피 → 라인 트레이싱 → 강화학습 → 웹 제어

## 🔧 하드웨어 구성

### 메인 컨트롤러
- **Raspberry Pi Zero 2 W** × 1개

### 센서 & 카메라
- **160도 광각 카메라 모듈** × 1개
- **22-to-15 FPC 카메라 케이블** × 1개
- **초음파 센서 HC-SR04** × 1개

### 모터 & 구동부
- **모터 드라이버 L298N** × 1개
- **기어 DC 모터** × 2개
- **바퀴** × 2개
- **볼 캐스터** × 1개

### 전원 & 연결
- **5V 전압 강하 모듈** × 1개
- **점퍼선** (여러개)

### 프레임 & 구조
- **1층 프레임** × 1개
- **2층 프레임** × 1개

## 📚 커리큘럼 구조

### 1단계: 하드웨어 조립 (`0.Guide/`)
```
📁 0.Guide/
├── 0_Hardware_Setup.md      # 하드웨어 조립 가이드
├── 1_OS_Install_SSH.md      # OS 설치 및 SSH 설정
└── 2_Usage_Flask_Dashboard.md # 웹 대시보드 사용법
```
- 하드웨어 조립 순서 및 각 부품 설명
- 라즈베리파이 OS 설치 방법
- SSH 연결 설정

### 2단계: 개별 컴포넌트 테스트 (`1.ComponentTest/`)
```
📁 1.ComponentTest/
├── motor_test.py     # 모터 제어 테스트
├── sonic_test.py     # 초음파 센서 테스트
└── camera_test.py    # 카메라 모듈 테스트
```
- 각 하드웨어 컴포넌트의 개별 동작 확인
- Flask 웹 대시보드를 통한 제어

### 3단계: 컴포넌트 클래스화 (`2.ComponentClass/`)
```
📁 2.ComponentClass/
├── _1.MotorClass/           # 모터 제어 클래스
├── _2.SonicClass/           # 초음파 센서 클래스
├── _3.CameraClass/          # 카메라 모듈 클래스
└── IntegratedClass.py       # 통합 메인 클래스
```
- 객체지향 프로그래밍으로 각 컴포넌트 클래스화
- 모든 기능을 통합한 `PathfinderKit` 클래스

### 4단계: 통합 테스트 (`3.IntegrationTest/`)
```
📁 3.IntegrationTest/
├── all_components_test.py   # 전체 컴포넌트 통합 테스트
└── test_all_components.py   # 통합 동작 확인
```
- 모든 컴포넌트가 함께 동작하는지 확인
- 하나의 대시보드에서 모든 기능 제어

### 5단계: 장애물 회피 (`4.ObstacleAvoidance/`)
```
📁 4.ObstacleAvoidance/
├── obstacle_avoidance.py    # 장애물 회피 알고리즘
└── obstacle_avoid.py        # 추가 구현
```
- 초음파 센서로 전방 장애물 감지
- 장애물 발견 시 랜덤 방향으로 회전 후 직진 반복

### 6단계: OpenCV + PID 라인 트레이싱 (`5.LineTracing_PID/`)
```
📁 5.LineTracing_PID/
├── line_tracer.py          # PID 제어 라인 트레이싱
└── pid_line_follow.py      # PID 알고리즘 구현
```
- OpenCV를 이용한 영상 처리
- PID 제어로 흰 배경의 검은색 선 따라가기

### 7단계: Q-Learning 자율주행 (`6.QLearning/`)
```
📁 6.QLearning/
├── q_learning_drive.py     # Q-Learning 자율주행 구현
├── q_learning_train.ipynb  # 학습 과정 시각화
├── q_table.npy            # 학습된 Q-테이블
└── README.md              # Q-Learning 상세 가이드
```
- 강화학습 알고리즘으로 자율주행 학습
- 환경과 상호작용하며 최적 경로 탐색

### 추가: 웹 인터페이스 (`7.WebUploader/`)
```
📁 7.WebUploader/
├── static/                 # CSS, JS, 이미지 파일
│   └── uploads/           # 업로드된 이미지 저장
├── templates/             # HTML 템플릿
│   └── index.html        # 메인 웹 인터페이스
├── web_controller.py      # Flask 웹 서버
├── test_web_controller.py # 하드웨어 없이 테스트
├── requirements.txt       # 웹 의존성 패키지
└── README.md             # 웹 인터페이스 가이드
```
- Flask 기반 실시간 웹 제어 대시보드
- 라이브 카메라 스트리밍
- 원격 로봇 제어 및 모니터링

## 🎓 학습 목표

### 하드웨어 & 임베디드
- GPIO 핀 제어 및 센서 인터페이싱
- PWM을 이용한 모터 속도 제어
- 실시간 센서 데이터 처리

### 소프트웨어 개발
- Python 객체지향 프로그래밍
- 모듈화 및 클래스 설계
- 멀티스레딩 및 비동기 처리

### 웹 개발
- Flask 웹 프레임워크
- RESTful API 설계
- 실시간 웹 통신 (WebSocket)

### 컴퓨터 비전
- OpenCV 영상 처리
- 색상 기반 객체 인식
- 실시간 이미지 분석

### 인공지능
- 강화학습 (Q-Learning)
- 상태-행동 매핑
- 탐험-활용 전략

### 제어 이론
- PID 제어 시스템
- 피드백 제어 루프
- 시스템 안정성

## 📖 학습 로드맵 (파이썬 초급자용)

### 🚀 1주차: 환경 설정 & 기초 확인
- [ ] 하드웨어 조립 완료
- [ ] 라즈베리파이 OS 설치 및 SSH 연결
- [ ] Python 기본 문법 복습 (변수, 함수, 클래스)
- [ ] GPIO 기본 개념 이해

### 🔧 2주차: 개별 컴포넌트 마스터
- [ ] 모터 제어 예제 실행 및 코드 분석
- [ ] 초음파 센서 데이터 읽기 및 시각화
- [ ] 카메라 모듈로 사진 촬영
- [ ] **미니 프로젝트**: 간단한 원격 조종 로봇

### 🔗 3주차: 통합 및 객체지향 프로그래밍
- [ ] IntegratedClass.py 코드 분석
- [ ] 클래스 상속과 모듈화 이해
- [ ] 멀티스레딩 개념 학습
- [ ] **미니 프로젝트**: 음성 명령으로 로봇 제어

### 🚧 4주차: 자율 행동 구현
- [ ] 장애물 회피 알고리즘 구현
- [ ] 센서 데이터 기반 의사결정 로직
- [ ] 상태 머신 패턴 학습
- [ ] **미니 프로젝트**: 미로 탈출 로봇

### 👁️ 5-6주차: 컴퓨터 비전
- [ ] OpenCV 기초 (이미지 처리, 색상 인식)
- [ ] PID 제어 이론 학습
- [ ] 라인 트레이싱 알고리즘 구현
- [ ] **미니 프로젝트**: 색상 추적 로봇

### 🧠 7-8주차: 인공지능 입문
- [ ] 강화학습 기본 개념
- [ ] Q-Learning 알고리즘 이해
- [ ] 학습 데이터 수집 및 분석
- [ ] **최종 프로젝트**: 자율주행 로봇 완성

### 🌐 추가 학습: 웹 개발
- [ ] Flask 웹 프레임워크 기초
- [ ] RESTful API 설계
- [ ] 실시간 웹 통신 (WebSocket)
- [ ] **확장 프로젝트**: 모바일 앱 연동

## 📋 시스템 요구사항

- **하드웨어**: Raspberry Pi Zero 2 W, 16GB+ microSD카드
- **OS**: Raspberry Pi OS Lite (32-bit) 또는 Desktop 버전
- **Python**: 3.7 이상
- **메모리**: 512MB RAM (Pi Zero 2 W 기본 사양)
- **네트워크**: Wi-Fi 내장 (2.4GHz 802.11 b/g/n)
- **전원**: 5V 2A 이상 권장

## 📦 의존성 패키지

### 핵심 라이브러리
```
RPi.GPIO>=0.7.0          # GPIO 제어
numpy>=1.19.5            # 수치 연산
opencv-python-headless   # 컴퓨터 비전
picamera2>=0.3.12        # 카메라 제어
```

### 웹 인터페이스
```
flask>=2.0.1             # 웹 프레임워크
flask-socketio>=5.1.1    # 실시간 통신
eventlet>=0.33.0         # 비동기 처리
```

### 유틸리티
```
python-dotenv>=0.19.0    # 환경 변수 관리
pyserial>=3.5            # 시리얼 통신
pytest>=6.2.5           # 테스트 프레임워크
```

## 🔧 문제 해결

### 일반적인 문제
- **GPIO 권한 오류**: `sudo` 권한으로 실행 또는 사용자를 `gpio` 그룹에 추가
- **카메라 인식 안됨**: `raspi-config`에서 카메라 활성화
- **웹 접속 불가**: 방화벽 설정 확인 및 포트 5000 개방

### 성능 최적화
- 이미지 해상도 조정으로 처리 속도 향상
- 센서 읽기 주기 최적화
- 메모리 사용량 모니터링

## 🎯 확장 프로젝트 아이디어

### 초급 확장
- **음성 제어**: 음성 인식으로 로봇 명령
- **LED 매트릭스**: 감정 표현 디스플레이
- **블루투스 조종**: 스마트폰 앱 연동
- **센서 융합**: 온도, 습도 센서 추가

### 중급 확장
- **SLAM**: 동시 위치 추정 및 지도 작성
- **객체 인식**: YOLO를 이용한 실시간 객체 탐지
- **군집 로봇**: 여러 로봇 협업 시스템
- **IoT 연동**: 클라우드 데이터 수집 및 분석

### 고급 확장
- **딥러닝**: CNN을 이용한 고급 영상 처리
- **ROS 연동**: Robot Operating System 활용
- **시뮬레이션**: Gazebo 가상 환경 연동
- **상용화**: 제품 수준의 UI/UX 개발

## 🏆 성취 배지 시스템

학습 동기 부여를 위한 단계별 성취 시스템:

### 🥉 브론즈 배지
- [ ] **첫 걸음**: 하드웨어 조립 완료
- [ ] **Hello Robot**: 첫 번째 모터 제어 성공
- [ ] **센서 마스터**: 모든 센서 데이터 읽기 성공
- [ ] **웹 개발자**: 웹 인터페이스 실행 성공

### 🥈 실버 배지
- [ ] **통합자**: 모든 컴포넌트 통합 성공
- [ ] **장애물 회피**: 자율 장애물 회피 구현
- [ ] **라인 트레이서**: PID 라인 트레이싱 성공
- [ ] **문제 해결사**: 독립적으로 버그 수정

### 🥇 골드 배지
- [ ] **AI 엔지니어**: Q-Learning 자율주행 완성
- [ ] **창작자**: 독창적인 확장 기능 개발
- [ ] **멘토**: 다른 학습자 도움 제공
- [ ] **마스터**: 모든 커리큘럼 완주

## 📄 라이선스

이 프로젝트는 MIT 라이선스 하에 배포됩니다. 자세한 내용은 [LICENSE](LICENSE) 파일을 참조하세요.

## 🙏 감사의 말

- **Flask**: 웹 프레임워크
- **OpenCV**: 컴퓨터 비전 라이브러리
- **Bootstrap**: UI 프레임워크
- **Raspberry Pi Foundation**: 하드웨어 플랫폼

---

**패스파인더 키트와 함께 자율주행 로봇의 세계를 탐험해보세요! 🤖✨**
