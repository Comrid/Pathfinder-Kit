#!/usr/bin/env python3
"""
ğŸ§  Q-Learning LineTracing System
íŒ¨ìŠ¤íŒŒì¸ë” í‚¤íŠ¸ìš© ê°•í™”í•™ìŠµ ê¸°ë°˜ ë¼ì¸ íŠ¸ë ˆì´ì‹± ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ

Features:
- ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë°
- Q-Learning ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ í•™ìŠµ
- ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ í•™ìŠµ ê³¼ì • ëª¨ë‹ˆí„°ë§
- ììœ¨ì£¼í–‰ ëª¨ë“œ ë° ìˆ˜ë™ ì œì–´ ëª¨ë“œ
"""

import os
import sys
import time
import json
import threading
import numpy as np
import cv2
from datetime import datetime
from flask import Flask, render_template, Response, request, jsonify
from flask_socketio import SocketIO, emit
import base64

# GPIO ëª¨ë“ˆ ê°€ìš©ì„± í™•ì¸
try:
    import RPi.GPIO as GPIO
    GPIO_AVAILABLE = True
    print("âœ… GPIO ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥ - í•˜ë“œì›¨ì–´ ëª¨ë“œ")
except ImportError:
    GPIO_AVAILABLE = False
    print("âš ï¸ GPIO ëª¨ë“ˆ ì—†ìŒ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")

# ì¹´ë©”ë¼ ëª¨ë“ˆ ê°€ìš©ì„± í™•ì¸
try:
    from picamera2 import Picamera2
    CAMERA_AVAILABLE = True
    print("âœ… PiCamera2 ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    try:
        import cv2
        CAMERA_AVAILABLE = True
        print("âš ï¸ PiCamera2 ì—†ìŒ - OpenCV ì¹´ë©”ë¼ ì‚¬ìš©")
    except ImportError:
        CAMERA_AVAILABLE = False
        print("âŒ ì¹´ë©”ë¼ ëª¨ë“ˆ ì—†ìŒ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")

# Flask ì•± ì„¤ì •
app = Flask(__name__)
app.config['SECRET_KEY'] = 'pathfinder-qlearning-linetracing'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# =============================================================================
# ì „ì—­ ë³€ìˆ˜ ë° ì„¤ì •
# =============================================================================

# ëª¨í„° ì œì–´ í•€ ì„¤ì •
IN1, IN2, IN3, IN4 = 23, 24, 22, 27  # ëª¨í„° ë°©í–¥ ì œì–´
ENA, ENB = 12, 13  # PWM í•€

# ì‹œìŠ¤í…œ ìƒíƒœ
system_running = True
learning_active = False
autonomous_mode = False
manual_control = False

# ìŠ¤ë ˆë“œ ë™ê¸°í™”
state_lock = threading.Lock()
camera_lock = threading.Lock()

# ì¹´ë©”ë¼ ì„¤ì •
camera = None
current_frame = None
processed_frame = None

# Q-Learning íŒŒë¼ë¯¸í„°
class QLearningConfig:
    """Q-Learning ì„¤ì • í´ë˜ìŠ¤"""
    def __init__(self):
        # í•™ìŠµ íŒŒë¼ë¯¸í„°
        self.learning_rate = 0.1      # í•™ìŠµë¥ 
        self.discount_factor = 0.95   # í• ì¸ ì¸ìˆ˜
        self.epsilon = 0.3            # íƒí—˜ë¥  (ì´ˆê¸°ê°’)
        self.epsilon_min = 0.01       # ìµœì†Œ íƒí—˜ë¥ 
        self.epsilon_decay = 0.995    # íƒí—˜ë¥  ê°ì†Œìœ¨
        
        # ìƒíƒœ ë° í–‰ë™ ê³µê°„
        self.num_states = 7           # ë¼ì¸ ìœ„ì¹˜ ìƒíƒœ (0: ì™¼ìª½ ë ~ 6: ì˜¤ë¥¸ìª½ ë)
        self.num_actions = 5          # í–‰ë™ (0: ì¢ŒíšŒì „, 1: ì•½ê°„ì¢Œ, 2: ì§ì§„, 3: ì•½ê°„ìš°, 4: ìš°íšŒì „)
        
        # ë³´ìƒ ì„¤ì •
        self.reward_on_line = 10      # ë¼ì¸ ìœ„ì— ìˆì„ ë•Œ ë³´ìƒ
        self.reward_off_line = -5     # ë¼ì¸ì—ì„œ ë²—ì–´ë‚¬ì„ ë•Œ í˜ë„í‹°
        self.reward_center = 15       # ì¤‘ì•™ì— ìˆì„ ë•Œ ì¶”ê°€ ë³´ìƒ
        
        # ëª¨í„° ì†ë„ ì„¤ì •
        self.base_speed = 60          # ê¸°ë³¸ ì†ë„
        self.turn_speed = 40          # íšŒì „ ì†ë„

# Q-Learning ì—ì´ì „íŠ¸
class QLearningAgent:
    """Q-Learning ê¸°ë°˜ ë¼ì¸ íŠ¸ë ˆì´ì‹± ì—ì´ì „íŠ¸"""
    
    def __init__(self, config):
        self.config = config
        self.q_table = np.zeros((config.num_states, config.num_actions))
        self.current_state = 3  # ì¤‘ì•™ ìƒíƒœë¡œ ì´ˆê¸°í™”
        self.current_action = 2  # ì§ì§„ìœ¼ë¡œ ì´ˆê¸°í™”
        self.episode = 0
        self.total_reward = 0
        self.episode_rewards = []
        self.learning_history = []
        
        # í†µê³„
        self.successful_episodes = 0
        self.total_steps = 0
        
    def get_state_from_line_position(self, line_center_x, frame_width):
        """ë¼ì¸ ì¤‘ì‹¬ ìœ„ì¹˜ë¥¼ ìƒíƒœë¡œ ë³€í™˜"""
        if line_center_x is None:
            return 3  # ë¼ì¸ì´ ì—†ìœ¼ë©´ ì¤‘ì•™ ìƒíƒœ
        
        # í”„ë ˆì„ì„ 7ê°œ êµ¬ì—­ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìƒíƒœ ê²°ì •
        section_width = frame_width / self.config.num_states
        state = int(line_center_x / section_width)
        return max(0, min(self.config.num_states - 1, state))
    
    def choose_action(self, state, training=True):
        """Îµ-greedy ì •ì±…ìœ¼ë¡œ í–‰ë™ ì„ íƒ"""
        if training and np.random.random() < self.config.epsilon:
            # íƒí—˜: ëœë¤ í–‰ë™
            action = np.random.randint(self.config.num_actions)
        else:
            # í™œìš©: ìµœì  í–‰ë™
            action = np.argmax(self.q_table[state])
        
        return action
    
    def update_q_table(self, state, action, reward, next_state):
        """Q-í…Œì´ë¸” ì—…ë°ì´íŠ¸"""
        current_q = self.q_table[state, action]
        max_next_q = np.max(self.q_table[next_state])
        
        # Q-Learning ì—…ë°ì´íŠ¸ ê³µì‹
        new_q = current_q + self.config.learning_rate * (
            reward + self.config.discount_factor * max_next_q - current_q
        )
        
        self.q_table[state, action] = new_q
        
        # í•™ìŠµ ê¸°ë¡
        self.learning_history.append({
            'episode': self.episode,
            'state': state,
            'action': action,
            'reward': reward,
            'q_value': new_q,
            'epsilon': self.config.epsilon
        })
    
    def calculate_reward(self, state, line_detected):
        """ë³´ìƒ ê³„ì‚°"""
        if not line_detected:
            return self.config.reward_off_line
        
        # ì¤‘ì•™ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ë³´ìƒ
        center_state = self.config.num_states // 2
        distance_from_center = abs(state - center_state)
        
        if distance_from_center == 0:
            return self.config.reward_center
        elif distance_from_center <= 1:
            return self.config.reward_on_line
        else:
            return self.config.reward_on_line - distance_from_center
    
    def end_episode(self):
        """ì—í”¼ì†Œë“œ ì¢…ë£Œ ì²˜ë¦¬"""
        self.episode_rewards.append(self.total_reward)
        
        # ì„±ê³µì ì¸ ì—í”¼ì†Œë“œ íŒì • (ì„ê³„ê°’ ì´ìƒì˜ ë³´ìƒ)
        if self.total_reward > 100:
            self.successful_episodes += 1
        
        # Îµ ê°ì†Œ
        if self.config.epsilon > self.config.epsilon_min:
            self.config.epsilon *= self.config.epsilon_decay
        
        self.episode += 1
        self.total_reward = 0
    
    def save_model(self, filepath):
        """Q-í…Œì´ë¸” ì €ì¥"""
        model_data = {
            'q_table': self.q_table.tolist(),
            'episode': self.episode,
            'epsilon': self.config.epsilon,
            'episode_rewards': self.episode_rewards,
            'successful_episodes': self.successful_episodes,
            'total_steps': self.total_steps
        }
        
        with open(filepath, 'w') as f:
            json.dump(model_data, f, indent=2)
        
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    def load_model(self, filepath):
        """Q-í…Œì´ë¸” ë¡œë“œ"""
        try:
            with open(filepath, 'r') as f:
                model_data = json.load(f)
            
            self.q_table = np.array(model_data['q_table'])
            self.episode = model_data.get('episode', 0)
            self.config.epsilon = model_data.get('epsilon', self.config.epsilon)
            self.episode_rewards = model_data.get('episode_rewards', [])
            self.successful_episodes = model_data.get('successful_episodes', 0)
            self.total_steps = model_data.get('total_steps', 0)
            
            print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filepath}")
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

# ì „ì—­ Q-Learning ì—ì´ì „íŠ¸
config = QLearningConfig()
agent = QLearningAgent(config)

# =============================================================================
# GPIO ë° ëª¨í„° ì œì–´
# =============================================================================

def setup_gpio():
    """GPIO ì´ˆê¸°í™”"""
    if GPIO_AVAILABLE:
        try:
            GPIO.setwarnings(False)
            GPIO.cleanup()
            GPIO.setmode(GPIO.BCM)
            
            # ëª¨í„° í•€ ì„¤ì •
            GPIO.setup(IN1, GPIO.OUT)
            GPIO.setup(IN2, GPIO.OUT)
            GPIO.setup(IN3, GPIO.OUT)
            GPIO.setup(IN4, GPIO.OUT)
            GPIO.setup(ENA, GPIO.OUT)
            GPIO.setup(ENB, GPIO.OUT)
            
            # PWM ì„¤ì •
            global pwm_right, pwm_left
            pwm_right = GPIO.PWM(ENA, 1000)
            pwm_left = GPIO.PWM(ENB, 1000)
            pwm_right.start(0)
            pwm_left.start(0)
            
            print("ğŸ”§ GPIO ì„¤ì • ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ GPIO ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    else:
        print("ğŸ”§ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ - GPIO ì„¤ì • ê±´ë„ˆëœ€")
        return True

def stop_motors():
    """ëª¨í„° ì •ì§€"""
    if GPIO_AVAILABLE:
        try:
            GPIO.output(IN1, GPIO.LOW)
            GPIO.output(IN2, GPIO.LOW)
            GPIO.output(IN3, GPIO.LOW)
            GPIO.output(IN4, GPIO.LOW)
            pwm_right.ChangeDutyCycle(0)
            pwm_left.ChangeDutyCycle(0)
        except:
            pass
    else:
        print("ğŸ® ì‹œë®¬ë ˆì´ì…˜: ëª¨í„° ì •ì§€")

def execute_action(action):
    """Q-Learning í–‰ë™ì„ ëª¨í„° ëª…ë ¹ìœ¼ë¡œ ë³€í™˜ ë° ì‹¤í–‰"""
    actions = {
        0: "turn_left",      # ì¢ŒíšŒì „
        1: "slight_left",    # ì•½ê°„ ì¢ŒíšŒì „
        2: "forward",        # ì§ì§„
        3: "slight_right",   # ì•½ê°„ ìš°íšŒì „
        4: "turn_right"      # ìš°íšŒì „
    }
    
    action_name = actions.get(action, "forward")
    
    if GPIO_AVAILABLE:
        try:
            if action == 0:  # ì¢ŒíšŒì „
                GPIO.output(IN1, GPIO.HIGH)
                GPIO.output(IN2, GPIO.LOW)
                GPIO.output(IN3, GPIO.LOW)
                GPIO.output(IN4, GPIO.HIGH)
                pwm_right.ChangeDutyCycle(config.turn_speed)
                pwm_left.ChangeDutyCycle(config.turn_speed)
            elif action == 1:  # ì•½ê°„ ì¢ŒíšŒì „
                GPIO.output(IN1, GPIO.HIGH)
                GPIO.output(IN2, GPIO.LOW)
                GPIO.output(IN3, GPIO.HIGH)
                GPIO.output(IN4, GPIO.LOW)
                pwm_right.ChangeDutyCycle(config.base_speed)
                pwm_left.ChangeDutyCycle(config.base_speed * 0.5)
            elif action == 2:  # ì§ì§„
                GPIO.output(IN1, GPIO.HIGH)
                GPIO.output(IN2, GPIO.LOW)
                GPIO.output(IN3, GPIO.HIGH)
                GPIO.output(IN4, GPIO.LOW)
                pwm_right.ChangeDutyCycle(config.base_speed)
                pwm_left.ChangeDutyCycle(config.base_speed)
            elif action == 3:  # ì•½ê°„ ìš°íšŒì „
                GPIO.output(IN1, GPIO.HIGH)
                GPIO.output(IN2, GPIO.LOW)
                GPIO.output(IN3, GPIO.HIGH)
                GPIO.output(IN4, GPIO.LOW)
                pwm_right.ChangeDutyCycle(config.base_speed * 0.5)
                pwm_left.ChangeDutyCycle(config.base_speed)
            elif action == 4:  # ìš°íšŒì „
                GPIO.output(IN1, GPIO.LOW)
                GPIO.output(IN2, GPIO.HIGH)
                GPIO.output(IN3, GPIO.HIGH)
                GPIO.output(IN4, GPIO.LOW)
                pwm_right.ChangeDutyCycle(config.turn_speed)
                pwm_left.ChangeDutyCycle(config.turn_speed)
        except Exception as e:
            print(f"âŒ ëª¨í„° ì œì–´ ì˜¤ë¥˜: {e}")
    else:
        print(f"ğŸ® ì‹œë®¬ë ˆì´ì…˜: {action_name} ì‹¤í–‰")
    
    return action_name

# =============================================================================
# ì»´í“¨í„° ë¹„ì „ - ë¼ì¸ ê²€ì¶œ
# =============================================================================

def detect_line(frame):
    """ë¼ì¸ ê²€ì¶œ ë° ì¤‘ì‹¬ì  ê³„ì‚°"""
    try:
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # ì´ì§„í™” (ê²€ì€ ë¼ì¸ ê²€ì¶œ)
        _, binary = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY_INV)
        
        # ê´€ì‹¬ ì˜ì—­ ì„¤ì • (í•˜ë‹¨ 1/3 ì˜ì—­)
        height, width = binary.shape
        roi_height = height // 3
        roi = binary[height - roi_height:height, :]
        
        # ì»¨íˆ¬ì–´ ì°¾ê¸°
        contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        line_center_x = None
        line_detected = False
        
        if contours:
            # ê°€ì¥ í° ì»¨íˆ¬ì–´ë¥¼ ë¼ì¸ìœ¼ë¡œ ê°„ì£¼
            largest_contour = max(contours, key=cv2.contourArea)
            
            if cv2.contourArea(largest_contour) > 100:  # ìµœì†Œ ë©´ì  í•„í„°
                # ì»¨íˆ¬ì–´ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
                M = cv2.moments(largest_contour)
                if M["m00"] != 0:
                    line_center_x = int(M["m10"] / M["m00"])
                    line_detected = True
                    
                    # ì‹œê°í™”ë¥¼ ìœ„í•´ ì»¨íˆ¬ì–´ ê·¸ë¦¬ê¸°
                    cv2.drawContours(roi, [largest_contour], -1, (255, 255, 255), 2)
                    cv2.circle(roi, (line_center_x, int(M["m01"] / M["m00"])), 5, (255, 255, 255), -1)
        
        # ì²˜ë¦¬ëœ í”„ë ˆì„ ìƒì„± (ì‹œê°í™”ìš©)
        processed = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)
        
        # ìƒíƒœ êµ¬ì—­ í‘œì‹œ
        section_width = width / config.num_states
        for i in range(config.num_states + 1):
            x = int(i * section_width)
            cv2.line(processed, (x, 0), (x, roi_height), (0, 255, 0), 1)
        
        # ë¼ì¸ ì¤‘ì‹¬ì  í‘œì‹œ
        if line_center_x is not None:
            cv2.line(processed, (line_center_x, 0), (line_center_x, roi_height), (0, 0, 255), 2)
        
        return line_center_x, line_detected, processed
        
    except Exception as e:
        print(f"âŒ ë¼ì¸ ê²€ì¶œ ì˜¤ë¥˜: {e}")
        return None, False, frame

# =============================================================================
# ì¹´ë©”ë¼ ê´€ë¦¬
# =============================================================================

def setup_camera():
    """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
    global camera
    
    if not CAMERA_AVAILABLE:
        print("âš ï¸ ì¹´ë©”ë¼ ì—†ìŒ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
        return False
    
    try:
        if GPIO_AVAILABLE:
            # Raspberry Pi ì¹´ë©”ë¼ ì‚¬ìš©
            camera = Picamera2()
            camera.configure(camera.create_preview_configuration(main={"size": (640, 480)}))
            camera.start()
            time.sleep(2)  # ì¹´ë©”ë¼ ì•ˆì •í™” ëŒ€ê¸°
            print("ğŸ“· PiCamera2 ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            # USB ì¹´ë©”ë¼ ì‚¬ìš©
            camera = cv2.VideoCapture(0)
            camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            print("ğŸ“· USB ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ")
        
        return True
    except Exception as e:
        print(f"âŒ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def capture_frame():
    """í”„ë ˆì„ ìº¡ì²˜"""
    global current_frame
    
    if not CAMERA_AVAILABLE or camera is None:
        # ì‹œë®¬ë ˆì´ì…˜ìš© ë”ë¯¸ í”„ë ˆì„ ìƒì„±
        dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        cv2.putText(dummy_frame, "SIMULATION MODE", (200, 240), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        return dummy_frame
    
    try:
        if GPIO_AVAILABLE and hasattr(camera, 'capture_array'):
            # PiCamera2
            frame = camera.capture_array()
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        else:
            # USB ì¹´ë©”ë¼
            ret, frame = camera.read()
            if not ret:
                return None
        
        with camera_lock:
            current_frame = frame.copy()
        
        return frame
    except Exception as e:
        print(f"âŒ í”„ë ˆì„ ìº¡ì²˜ ì˜¤ë¥˜: {e}")
        return None

def generate_frames():
    """ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°ìš© í”„ë ˆì„ ìƒì„±ê¸°"""
    while system_running:
        frame = capture_frame()
        if frame is not None:
            try:
                # JPEG ì¸ì½”ë”©
                _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                frame_bytes = buffer.tobytes()
                
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            except Exception as e:
                print(f"âŒ í”„ë ˆì„ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
        
        time.sleep(0.033)  # ~30 FPS

# =============================================================================
# Q-Learning í•™ìŠµ ìŠ¤ë ˆë“œ
# =============================================================================

def learning_thread():
    """Q-Learning í•™ìŠµ ë©”ì¸ ìŠ¤ë ˆë“œ"""
    global learning_active, autonomous_mode
    
    print("ğŸ§  Q-Learning í•™ìŠµ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    step_count = 0
    episode_start_time = time.time()
    
    while system_running:
        if not learning_active:
            time.sleep(0.1)
            continue
        
        try:
            # í˜„ì¬ í”„ë ˆì„ íšë“
            frame = capture_frame()
            if frame is None:
                time.sleep(0.1)
                continue
            
            # ë¼ì¸ ê²€ì¶œ
            line_center_x, line_detected, processed_frame = detect_line(frame)
            
            # í˜„ì¬ ìƒíƒœ ê³„ì‚°
            current_state = agent.get_state_from_line_position(line_center_x, frame.shape[1])
            
            # í–‰ë™ ì„ íƒ
            action = agent.choose_action(current_state, training=True)
            
            # í–‰ë™ ì‹¤í–‰
            action_name = execute_action(action)
            
            # ë³´ìƒ ê³„ì‚°
            reward = agent.calculate_reward(current_state, line_detected)
            agent.total_reward += reward
            
            # Q-í…Œì´ë¸” ì—…ë°ì´íŠ¸ (ì´ì „ ìƒíƒœê°€ ìˆëŠ” ê²½ìš°)
            if hasattr(agent, 'prev_state') and hasattr(agent, 'prev_action'):
                agent.update_q_table(agent.prev_state, agent.prev_action, reward, current_state)
            
            # í˜„ì¬ ìƒíƒœ ì €ì¥
            agent.prev_state = current_state
            agent.prev_action = action
            agent.total_steps += 1
            step_count += 1
            
            # ì‹¤ì‹œê°„ í•™ìŠµ ì •ë³´ ì „ì†¡
            learning_info = {
                'episode': agent.episode,
                'step': step_count,
                'state': current_state,
                'action': action,
                'action_name': action_name,
                'reward': reward,
                'total_reward': agent.total_reward,
                'epsilon': agent.config.epsilon,
                'line_detected': line_detected,
                'line_center_x': line_center_x,
                'q_values': agent.q_table[current_state].tolist(),
                'timestamp': time.time()
            }
            
            socketio.emit('learning_update', learning_info)
            
            # ì²˜ë¦¬ëœ í”„ë ˆì„ ì „ì†¡
            if processed_frame is not None:
                _, buffer = cv2.imencode('.jpg', processed_frame)
                processed_b64 = base64.b64encode(buffer).decode('utf-8')
                socketio.emit('processed_frame', {'image': processed_b64})
            
            # ì—í”¼ì†Œë“œ ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            episode_duration = time.time() - episode_start_time
            if step_count >= 1000 or episode_duration > 60:  # 1000ìŠ¤í… ë˜ëŠ” 60ì´ˆ
                agent.end_episode()
                
                # ì—í”¼ì†Œë“œ ì™„ë£Œ ì •ë³´ ì „ì†¡
                episode_info = {
                    'episode': agent.episode,
                    'total_reward': agent.episode_rewards[-1] if agent.episode_rewards else 0,
                    'steps': step_count,
                    'duration': episode_duration,
                    'success_rate': agent.successful_episodes / max(agent.episode, 1) * 100,
                    'epsilon': agent.config.epsilon
                }
                
                socketio.emit('episode_complete', episode_info)
                
                # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì¤€ë¹„
                step_count = 0
                episode_start_time = time.time()
                
                # ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë¸ ì €ì¥
                if agent.episode % 10 == 0:
                    agent.save_model('q_learning_model.json')
            
            time.sleep(0.1)  # 10 FPSë¡œ í•™ìŠµ
            
        except Exception as e:
            print(f"âŒ í•™ìŠµ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            time.sleep(1)
    
    print("ğŸ§  Q-Learning í•™ìŠµ ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# =============================================================================
# ììœ¨ì£¼í–‰ ìŠ¤ë ˆë“œ
# =============================================================================

def autonomous_thread():
    """ììœ¨ì£¼í–‰ ëª¨ë“œ ìŠ¤ë ˆë“œ"""
    global autonomous_mode
    
    print("ğŸš— ììœ¨ì£¼í–‰ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    while system_running:
        if not autonomous_mode:
            time.sleep(0.1)
            continue
        
        try:
            # í˜„ì¬ í”„ë ˆì„ íšë“
            frame = capture_frame()
            if frame is None:
                time.sleep(0.1)
                continue
            
            # ë¼ì¸ ê²€ì¶œ
            line_center_x, line_detected, processed_frame = detect_line(frame)
            
            # í˜„ì¬ ìƒíƒœ ê³„ì‚°
            current_state = agent.get_state_from_line_position(line_center_x, frame.shape[1])
            
            # ìµœì  í–‰ë™ ì„ íƒ (íƒí—˜ ì—†ìŒ)
            action = agent.choose_action(current_state, training=False)
            
            # í–‰ë™ ì‹¤í–‰
            action_name = execute_action(action)
            
            # ììœ¨ì£¼í–‰ ì •ë³´ ì „ì†¡
            autonomous_info = {
                'state': current_state,
                'action': action,
                'action_name': action_name,
                'line_detected': line_detected,
                'line_center_x': line_center_x,
                'confidence': np.max(agent.q_table[current_state]),
                'timestamp': time.time()
            }
            
            socketio.emit('autonomous_update', autonomous_info)
            
            time.sleep(0.1)  # 10 FPSë¡œ ììœ¨ì£¼í–‰
            
        except Exception as e:
            print(f"âŒ ììœ¨ì£¼í–‰ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            time.sleep(1)
    
    print("ğŸš— ììœ¨ì£¼í–‰ ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# =============================================================================
# Flask ë¼ìš°íŠ¸
# =============================================================================

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    """ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°"""
    return Response(generate_frames(),
                   mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/api/status')
def get_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    return jsonify({
        'learning_active': learning_active,
        'autonomous_mode': autonomous_mode,
        'manual_control': manual_control,
        'episode': agent.episode,
        'total_steps': agent.total_steps,
        'success_rate': agent.successful_episodes / max(agent.episode, 1) * 100,
        'epsilon': agent.config.epsilon,
        'gpio_available': GPIO_AVAILABLE,
        'camera_available': CAMERA_AVAILABLE
    })

@app.route('/api/q_table')
def get_q_table():
    """Q-í…Œì´ë¸” ì¡°íšŒ"""
    return jsonify({
        'q_table': agent.q_table.tolist(),
        'states': config.num_states,
        'actions': config.num_actions,
        'action_names': ['ì¢ŒíšŒì „', 'ì•½ê°„ì¢Œ', 'ì§ì§„', 'ì•½ê°„ìš°', 'ìš°íšŒì „']
    })

@app.route('/api/statistics')
def get_statistics():
    """í•™ìŠµ í†µê³„ ì¡°íšŒ"""
    return jsonify({
        'episode_rewards': agent.episode_rewards[-50:],  # ìµœê·¼ 50 ì—í”¼ì†Œë“œ
        'learning_history': agent.learning_history[-100:],  # ìµœê·¼ 100 ìŠ¤í…
        'total_episodes': agent.episode,
        'successful_episodes': agent.successful_episodes,
        'total_steps': agent.total_steps,
        'current_epsilon': agent.config.epsilon
    })

# =============================================================================
# SocketIO ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# =============================================================================

@socketio.on('connect')
def handle_connect():
    """í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
    print(f"ğŸ”— í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {request.sid}")
    emit('system_status', {
        'gpio_available': GPIO_AVAILABLE,
        'camera_available': CAMERA_AVAILABLE,
        'learning_active': learning_active,
        'autonomous_mode': autonomous_mode
    })

@socketio.on('disconnect')
def handle_disconnect():
    """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ"""
    print(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ: {request.sid}")

@socketio.on('start_learning')
def handle_start_learning():
    """í•™ìŠµ ì‹œì‘"""
    global learning_active, autonomous_mode, manual_control
    
    with state_lock:
        learning_active = True
        autonomous_mode = False
        manual_control = False
    
    print("ğŸ§  Q-Learning í•™ìŠµ ì‹œì‘")
    emit('learning_started', {'message': 'Q-Learning í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.'})

@socketio.on('stop_learning')
def handle_stop_learning():
    """í•™ìŠµ ì¤‘ì§€"""
    global learning_active
    
    with state_lock:
        learning_active = False
    
    stop_motors()
    print("ğŸ§  Q-Learning í•™ìŠµ ì¤‘ì§€")
    emit('learning_stopped', {'message': 'Q-Learning í•™ìŠµì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.'})

@socketio.on('start_autonomous')
def handle_start_autonomous():
    """ììœ¨ì£¼í–‰ ì‹œì‘"""
    global autonomous_mode, learning_active, manual_control
    
    with state_lock:
        autonomous_mode = True
        learning_active = False
        manual_control = False
    
    print("ğŸš— ììœ¨ì£¼í–‰ ëª¨ë“œ ì‹œì‘")
    emit('autonomous_started', {'message': 'ììœ¨ì£¼í–‰ ëª¨ë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.'})

@socketio.on('stop_autonomous')
def handle_stop_autonomous():
    """ììœ¨ì£¼í–‰ ì¤‘ì§€"""
    global autonomous_mode
    
    with state_lock:
        autonomous_mode = False
    
    stop_motors()
    print("ğŸš— ììœ¨ì£¼í–‰ ëª¨ë“œ ì¤‘ì§€")
    emit('autonomous_stopped', {'message': 'ììœ¨ì£¼í–‰ ëª¨ë“œê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.'})

@socketio.on('manual_control')
def handle_manual_control(data):
    """ìˆ˜ë™ ì œì–´"""
    global manual_control, learning_active, autonomous_mode
    
    if learning_active or autonomous_mode:
        emit('error', {'message': 'í•™ìŠµ ë˜ëŠ” ììœ¨ì£¼í–‰ ëª¨ë“œì—ì„œëŠ” ìˆ˜ë™ ì œì–´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
        return
    
    manual_control = True
    command = data.get('command', 'stop')
    
    # ìˆ˜ë™ ì œì–´ ëª…ë ¹ ì‹¤í–‰
    if command == 'forward':
        execute_action(2)  # ì§ì§„
    elif command == 'left':
        execute_action(0)  # ì¢ŒíšŒì „
    elif command == 'right':
        execute_action(4)  # ìš°íšŒì „
    elif command == 'stop':
        stop_motors()
    
    emit('manual_executed', {'command': command})

@socketio.on('save_model')
def handle_save_model():
    """ëª¨ë¸ ì €ì¥"""
    try:
        filename = f"q_learning_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        agent.save_model(filename)
        emit('model_saved', {'message': f'ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}'})
    except Exception as e:
        emit('error', {'message': f'ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}'})

@socketio.on('load_model')
def handle_load_model(data):
    """ëª¨ë¸ ë¡œë“œ"""
    try:
        filename = data.get('filename', 'q_learning_model.json')
        if agent.load_model(filename):
            emit('model_loaded', {'message': f'ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {filename}'})
        else:
            emit('error', {'message': f'ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {filename}'})
    except Exception as e:
        emit('error', {'message': f'ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {str(e)}'})

@socketio.on('reset_learning')
def handle_reset_learning():
    """í•™ìŠµ ì´ˆê¸°í™”"""
    global agent
    
    # í•™ìŠµ ì¤‘ì§€
    with state_lock:
        learning_active = False
        autonomous_mode = False
    
    stop_motors()
    
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    agent = QLearningAgent(config)
    
    print("ğŸ”„ Q-Learning ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    emit('learning_reset', {'message': 'Q-Learningì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.'})

# =============================================================================
# ë©”ì¸ ì‹¤í–‰
# =============================================================================

def cleanup():
    """ì‹œìŠ¤í…œ ì •ë¦¬"""
    global system_running, camera
    
    print("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
    
    system_running = False
    
    # ëª¨í„° ì •ì§€
    stop_motors()
    
    # ì¹´ë©”ë¼ ì •ë¦¬
    if camera is not None:
        try:
            if hasattr(camera, 'stop'):
                camera.stop()
            elif hasattr(camera, 'release'):
                camera.release()
        except:
            pass
    
    # GPIO ì •ë¦¬
    if GPIO_AVAILABLE:
        try:
            if 'pwm_right' in globals():
                pwm_right.stop()
            if 'pwm_left' in globals():
                pwm_left.stop()
            GPIO.cleanup()
        except:
            pass
    
    print("âœ… ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")

if __name__ == '__main__':
    try:
        print("ğŸš€ íŒ¨ìŠ¤íŒŒì¸ë” Q-Learning LineTracing ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 60)
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if not setup_gpio():
            print("âš ï¸ GPIO ì„¤ì • ì‹¤íŒ¨ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ê³„ì†")
        
        if not setup_camera():
            print("âš ï¸ ì¹´ë©”ë¼ ì„¤ì • ì‹¤íŒ¨ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ê³„ì†")
        
        # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹œë„
        if os.path.exists('q_learning_model.json'):
            agent.load_model('q_learning_model.json')
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        learning_thread_obj = threading.Thread(target=learning_thread, daemon=True)
        autonomous_thread_obj = threading.Thread(target=autonomous_thread, daemon=True)
        
        learning_thread_obj.start()
        autonomous_thread_obj.start()
        
        print("ğŸŒ ì›¹ ì„œë²„ ì‹œì‘: http://0.0.0.0:5000")
        print("ğŸ“± ëª¨ë°”ì¼ì—ì„œ ì ‘ì†: http://ë¼ì¦ˆë² ë¦¬íŒŒì´IP:5000")
        print("ğŸ›‘ Ctrl+Cë¡œ ì¢…ë£Œ")
        
        # Flask-SocketIO ì„œë²„ ì‹¤í–‰
        socketio.run(app, host='0.0.0.0', port=5000, debug=False)
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•œ ì¢…ë£Œ")
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    finally:
        cleanup()
